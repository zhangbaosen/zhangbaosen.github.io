<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Baosen Zhang</title>
    <description>Baosen Zhang is an Assistant Professor in the Electrical and Computer Engineering Department at the University of Washington. 
</description>
    <link>http://faculty.washington.edu/zhangbao//</link>
    <atom:link href="http://faculty.washington.edu/zhangbao//feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Fri, 17 Apr 2020 20:34:10 -0700</pubDate>
    <lastBuildDate>Fri, 17 Apr 2020 20:34:10 -0700</lastBuildDate>
    <generator>Jekyll v4.0.0</generator>
    
      <item>
        <title>Paper on Learning to Solve Network Flow Problems via Neural Decoding</title>
        <description>&lt;p&gt;Problems in power systems and operations research require repeatedly solving large-scale linear programming problems with a large number of different inputs. In energy systems with high levels of uncertain renewable resources, tens of thousands of scenarios may need to be solved every few minutes. Standard iterative algorithms for linear network flow problems, even though highly efficient, becomes a bottleneck in these applications. In this work, we propose a novel learning approach to accelerate the solving process. By leveraging the rich theory and economic interpretations of LP duality, we interpret the output of the neural network as a noisy codeword, where the codebook is given by the optimization problem’s KKT conditions. We propose a feedforward decoding strategy that finds the optimal set of active constraints. This design is error correcting and can offer orders of magnitude speedup compared to current state-of-the-art iterative solvers, while providing much better solutions in terms of feasibility and optimality compared to end-to-end learning approaches.&lt;/p&gt;

&lt;ol class=&quot;bibliography&quot;&gt;&lt;li&gt;&lt;span id=&quot;chen2020learning&quot;&gt;Y. Chen and B. Zhang, “Learning to Solve Network Flow Problems via Neural Decoding,” &lt;i&gt;arXiv preprint arXiv:2002.04091&lt;/i&gt;, 2020. &lt;/span&gt;

&lt;div id=&quot;chen2020learning-materials&quot;&gt;
  &lt;ul class=&quot;nav nav-pills&quot;&gt;
    

 &lt;li&gt;&lt;a data-toggle=&quot;collapse&quot; href=&quot;javascript:toggleDiv('chen2020learning-bibtex')&quot;&gt;BibTeX&lt;/a&gt;&lt;/li&gt;
    &lt;div id=&quot;chen2020learning-bibtex&quot; style=&quot;display:none;&quot;&gt;
    &lt;pre class=&quot;collapse&quot;&gt;@article{chen2020learning,
  title = {Learning to Solve Network Flow Problems via Neural Decoding},
  author = {Chen, Yize and Zhang, Baosen},
  journal = {arXiv preprint arXiv:2002.04091},
  year = {2020},
  link = {https://arxiv.org/abs/2002.04091},
  blog = {2020-02-20}
}
&lt;/pre&gt;
    &lt;/div&gt;

    
    &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/2002.04091&quot;&gt;Download&lt;/a&gt;&lt;/li&gt;
    

  &lt;/ul&gt;


&lt;/div&gt;&lt;/li&gt;&lt;/ol&gt;
</description>
        <pubDate>Thu, 20 Feb 2020 00:00:00 -0800</pubDate>
        <link>http://faculty.washington.edu/zhangbao//blog/2020/02/ICML</link>
        <guid isPermaLink="true">http://faculty.washington.edu/zhangbao//blog/2020/02/ICML</guid>
        
        
        <category>new</category>
        
        <category>papers</category>
        
      </item>
    
      <item>
        <title>Input Convex Neural Networks for Optimal Voltage Regulation</title>
        <description>&lt;p&gt;The increasing penetration of renewables in distribution networks calls for faster and more advanced voltage regulation strategies. A promising approach is to formulate the problem as an optimization problem, where the optimal reactive power injection from inverters are calculated to maintain the voltages while satisfying power network constraints. However, existing optimization algorithms require the exact topology and line parameters of underlying distribution system, which are not known for most cases and are difficult to infer. In this paper, we propose to use specifically designed neural network to tackle the learning and optimization problem together. In the training stage, the proposed input convex neural network learns the mapping between the power injections and the voltages. In the voltage regulation stage, such trained network can find the optimal reactive power injections by design. We also provide a practical distributed algorithm by using the trained neural network. Theoretical bounds on the representation performance and learning efficiency of proposed model are also discussed. Numerical simulations on multiple test systems are conducted to illustrate the operation of the algorithm.&lt;/p&gt;

&lt;ol class=&quot;bibliography&quot;&gt;&lt;li&gt;&lt;span id=&quot;chen2020input&quot;&gt;Y. Chen, Y. Shi, and B. Zhang, “Input Convex Neural Networks for Optimal Voltage Regulation,” 2020. &lt;/span&gt;

&lt;div id=&quot;chen2020input-materials&quot;&gt;
  &lt;ul class=&quot;nav nav-pills&quot;&gt;
    

 &lt;li&gt;&lt;a data-toggle=&quot;collapse&quot; href=&quot;javascript:toggleDiv('chen2020input-bibtex')&quot;&gt;BibTeX&lt;/a&gt;&lt;/li&gt;
    &lt;div id=&quot;chen2020input-bibtex&quot; style=&quot;display:none;&quot;&gt;
    &lt;pre class=&quot;collapse&quot;&gt;@article{chen2020input,
  title = {Input Convex Neural Networks for Optimal Voltage Regulation},
  author = {Chen, Yize and Shi, Yuanyuan and Zhang, Baosen},
  year = {2020},
  eprint = {2002.08684},
  link = {https://arxiv.org/abs/2002.08684},
  blog = {2020-02-19}
}
&lt;/pre&gt;
    &lt;/div&gt;

    
    &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/2002.08684&quot;&gt;Download&lt;/a&gt;&lt;/li&gt;
    

  &lt;/ul&gt;


&lt;/div&gt;&lt;/li&gt;&lt;/ol&gt;
</description>
        <pubDate>Wed, 19 Feb 2020 00:00:00 -0800</pubDate>
        <link>http://faculty.washington.edu/zhangbao//blog/2020/02/TCNS</link>
        <guid isPermaLink="true">http://faculty.washington.edu/zhangbao//blog/2020/02/TCNS</guid>
        
        
        <category>new</category>
        
        <category>papers</category>
        
      </item>
    
      <item>
        <title>Invited Speaker at DOE AI Event</title>
        <description>&lt;p&gt;I was an invented speaker at the Innovation XLab, attended by most of the DOE and National Lab leadership. For more details, see the article by our department: &lt;a href=&quot;https://www.ece.uw.edu/spotlight/baosen-zhang-ai/&quot;&gt;Baosen Zhang serves as panelist at DOE Artificial Intelligence Summit&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Wed, 09 Oct 2019 00:00:00 -0700</pubDate>
        <link>http://faculty.washington.edu/zhangbao//blog/2019/10/DOE</link>
        <guid isPermaLink="true">http://faculty.washington.edu/zhangbao//blog/2019/10/DOE</guid>
        
        
        <category>new</category>
        
        <category>papers</category>
        
      </item>
    
      <item>
        <title>Bolun Xu to Join Columbia University as an Assistant Professor </title>
        <description>&lt;p&gt;Congrats to &lt;a href=&quot;https://bolunxu.github.io/&quot;&gt;Bolun&lt;/a&gt; who will join Columbia University in Jan of 2020.&lt;/p&gt;
</description>
        <pubDate>Wed, 09 Oct 2019 00:00:00 -0700</pubDate>
        <link>http://faculty.washington.edu/zhangbao//blog/2019/10/Bolun</link>
        <guid isPermaLink="true">http://faculty.washington.edu/zhangbao//blog/2019/10/Bolun</guid>
        
        
        <category>new</category>
        
        <category>papers</category>
        
      </item>
    
      <item>
        <title>Paper in ACM E-Energy: Exploiting Vulnerabilities of Load Forecasting Through Adversarial Attacks (Runner Up for Best Paper)</title>
        <description>&lt;p&gt;To appear as a paper in ACM E-Energy. We study how an adversary might attack forecasting techniques in power systems and analyze the potential impact on system operations, such as load shedding and increased dispatch costs. These types attack shows that forecasting techniques can be vulnerable to cyber security threats even when the adversary has no information about the system under attack and very little information about the forecasting algorithms themselves (compared to standard data injection attacks which require full knowledge of the system topology). &lt;a href=&quot;https://github.com/chennnnnyize/load_forecasts_attack&quot;&gt;Code&lt;/a&gt;&lt;/p&gt;

&lt;ol class=&quot;bibliography&quot;&gt;&lt;/ol&gt;
</description>
        <pubDate>Sat, 15 Jun 2019 00:00:00 -0700</pubDate>
        <link>http://faculty.washington.edu/zhangbao//blog/2019/06/Eenergy</link>
        <guid isPermaLink="true">http://faculty.washington.edu/zhangbao//blog/2019/06/Eenergy</guid>
        
        
        <category>new</category>
        
        <category>papers</category>
        
      </item>
    
      <item>
        <title>Paper in ICLR: designing convex neural networks for control</title>
        <description>&lt;p&gt;To appear as a paper in ICLR. We design a class of neural networks to be input-convex, which achieves excellent learning plus control performances on tasks such as Mujoco locomotion and building energy management.&lt;/p&gt;

&lt;ol class=&quot;bibliography&quot;&gt;&lt;/ol&gt;
</description>
        <pubDate>Thu, 10 Jan 2019 00:00:00 -0800</pubDate>
        <link>http://faculty.washington.edu/zhangbao//blog/2019/01/ICLR</link>
        <guid isPermaLink="true">http://faculty.washington.edu/zhangbao//blog/2019/01/ICLR</guid>
        
        
        <category>new</category>
        
        <category>papers</category>
        
      </item>
    
      <item>
        <title>Outreach at the Seattle Science Center</title>
        <description>&lt;p&gt;Thanks to Chase, Ling, Tinu, Tanner and Victor for putting on a booth at the Seattle Science Center! We had demos of our research (joint with &lt;a href=&quot;http://faculty.washington.edu/ratliffl/&quot;&gt;Lilian Ratliff&lt;/a&gt;), as well as props illustrating &lt;a href=&quot;https://en.wikipedia.org/wiki/Ford%E2%80%93Fulkerson_algorithm&quot;&gt;max-flow/min-cut&lt;/a&gt; and the &lt;a href=&quot;https://en.wikipedia.org/wiki/Monty_Hall_problem&quot;&gt;Monty Hall&lt;/a&gt; problem. Surprising, kids got the Monty Hall faster than the adults!&lt;/p&gt;

&lt;p float=&quot;left&quot;&gt;
  &lt;img src=&quot;https://www.dropbox.com/s/igs6xzrx3v7tgud/20180923_163749.jpg?raw=1&quot; alt=&quot; &quot; width=&quot;250&quot; height=&quot;250&quot; /&gt;
  &lt;img src=&quot;https://www.dropbox.com/s/6wgjpk1dfke2mzz/20180923_105408.jpg?raw=1&quot; alt=&quot; &quot; width=&quot;250&quot; height=&quot;250&quot; /&gt;
  &lt;img src=&quot;https://www.dropbox.com/s/4nc0x98bxb3p12t/IMAG3556.jpg?raw=1&quot; alt=&quot; &quot; width=&quot;250&quot; height=&quot;250&quot; /&gt;
&lt;/p&gt;

&lt;p float=&quot;left&quot;&gt;
  &lt;img src=&quot;https://www.dropbox.com/s/r8ezo8rtusmmyp2/20180922_144433.jpg?raw=1&quot; alt=&quot; &quot; width=&quot;250&quot; height=&quot;250&quot; /&gt;
  &lt;img src=&quot;https://www.dropbox.com/s/1psdx30pbti61rl/IMAG3554.jpg?raw=1&quot; alt=&quot; &quot; width=&quot;250&quot; height=&quot;250&quot; /&gt;
&lt;/p&gt;
</description>
        <pubDate>Sun, 23 Sep 2018 00:00:00 -0700</pubDate>
        <link>http://faculty.washington.edu/zhangbao//blog/2018/09/Science_center</link>
        <guid isPermaLink="true">http://faculty.washington.edu/zhangbao//blog/2018/09/Science_center</guid>
        
        
        <category>new</category>
        
        <category>papers</category>
        
      </item>
    
  </channel>
</rss>
