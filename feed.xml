<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Baosen Zhang</title>
    <description>Baosen Zhang is an Associate Professor in the Electrical and Computer Engineering Department at the University of Washington.
</description>
    <link>http://localhost:4000/</link>
    <atom:link href="http://localhost:4000/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Fri, 20 Jan 2023 12:42:30 -0800</pubDate>
    <lastBuildDate>Fri, 20 Jan 2023 12:42:30 -0800</lastBuildDate>
    <generator>Jekyll v4.2.1</generator>
    
      <item>
        <title>Paper on Efficient Reinforcement Learning Through Trajectory Generation</title>
        <description>&lt;p&gt;A key barrier to using reinforcement learning (RL) in many real-world applications is the requirement of a large number of system interactions to learn a good control policy. Off-policy and Offline RL methods have been proposed to reduce the number of interactions with the physical environment by learning control policies from historical data. However, their performances suffer from the lack of exploration and the distributional shifts in trajectories once controllers are updated. Moreover, most RL methods require that all states are directly observed, which is difficult to be attained in many settings. To overcome these challenges, we propose a trajectory generation algorithm, which adaptively generates new trajectories as if the system is being operated and explored under the updated control policies. Motivated by the fundamental lemma for linear systems, assuming sufficient excitation, we generate trajectories from linear combinations of historical trajectories. For linear feedback control, we prove that the algorithm generates trajectories with the exact distribution as if they are sampled from the real system using the updated control policy. In particular, the algorithm extends to systems where the states are not directly observed. Experiments show that the proposed method significantly reduces the number of sampled data needed for RL algorithms.&lt;/p&gt;
&lt;ol class=&quot;bibliography&quot;&gt;&lt;li&gt;&lt;span id=&quot;cui2022efficient&quot;&gt;W. Cui, L. Huang, W. Yang, and B. Zhang, “Efficient Reinforcement Learning Through Trajectory Generation,” &lt;i&gt;arXiv preprint arXiv:2211.17249&lt;/i&gt;, 2022. &lt;/span&gt;

&lt;div id=&quot;cui2022efficient-materials&quot;&gt;
  &lt;ul class=&quot;nav nav-pills&quot;&gt;
    

 &lt;li&gt;&lt;a data-toggle=&quot;collapse&quot; href=&quot;javascript:toggleDiv(&apos;cui2022efficient-bibtex&apos;)&quot;&gt;BibTeX&lt;/a&gt;&lt;/li&gt;
    &lt;div id=&quot;cui2022efficient-bibtex&quot; style=&quot;display:none;&quot;&gt;
    &lt;pre class=&quot;collapse&quot;&gt;@article{cui2022efficient,
  title = {Efficient Reinforcement Learning Through Trajectory Generation},
  author = {Cui, Wenqi and Huang, Linbin and Yang, Weiwei and Zhang, Baosen},
  journal = {arXiv preprint arXiv:2211.17249},
  year = {2022},
  blog = {2023-1-19},
  link = {https://arxiv.org/abs/2211.17249}
}
&lt;/pre&gt;
    &lt;/div&gt;

    
    &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/2211.17249&quot;&gt;Download&lt;/a&gt;&lt;/li&gt;
    

  &lt;/ul&gt;


&lt;/div&gt;&lt;/li&gt;&lt;/ol&gt;
</description>
        <pubDate>Thu, 19 Jan 2023 00:00:00 -0800</pubDate>
        <link>http://localhost:4000/blog/2023/01/L4DC_trajectory</link>
        <guid isPermaLink="true">http://localhost:4000/blog/2023/01/L4DC_trajectory</guid>
        
        
        <category>new</category>
        
        <category>papers</category>
        
      </item>
    
      <item>
        <title>Decentralized Safe Reinforcement Learning for Voltage Control</title>
        <description>&lt;p&gt;As more inverter-connected renewable resources are integrated into the grid, frequency stability may degrade because of the reduction in mechanical inertia and damping. A common approach to mitigate this degradation in performance is to use the power electronic interfaces of the renewable resources for primary frequency control. Since inverter-connected resources can realize almost arbitrary responses to frequency changes, they are not limited to reproducing the linear droop behaviors. To fully leverage their capabilities, reinforcement learning (RL) has emerged as a popular method to design nonlinear controllers to optimize a host of objective functions.
Because both inverter-connected resources and synchronous generators would be a significant part of the grid in the near and intermediate future, the learned controller of the former should be stabilizing with respect to the nonlinear dynamics of the latter. To overcome this challenge, we explicitly engineer the structure of neural network-based controllers such that they guarantee system stability by construction, through the use of a Lyapunov function. A recurrent neural network architecture is used to efficiently train the controllers. The resulting controllers only use local information and outperform optimal linear droop as well as other state-of-the-art learning approaches.&lt;/p&gt;

&lt;ol class=&quot;bibliography&quot;&gt;&lt;/ol&gt;
</description>
        <pubDate>Sun, 20 Feb 2022 00:00:00 -0800</pubDate>
        <link>http://localhost:4000/blog/2022/02/Voltage</link>
        <guid isPermaLink="true">http://localhost:4000/blog/2022/02/Voltage</guid>
        
        
        <category>new</category>
        
        <category>papers</category>
        
      </item>
    
      <item>
        <title>Paper on Predicting Power System Dynamics and Transients using a Frequency Domain Approach</title>
        <description>&lt;p&gt;The dynamics of power grids are governed by a large number of nonlinear ordinary differential equations (ODEs). To safely operate the system, operators need to check that the states described by this set of ODEs stay within prescribed limits after various faults. Limited by the size and stiffness of the ODEs, current numerical integration techniques are often too slow to be useful in real-time or large-scale resource allocation problems. In addition, detailed system parameters are often not exactly known. Machine learning approaches have been proposed to reduce the computational efforts, but existing methods generally suffer from overfitting and failures to predict unstable behaviors.
This paper proposes a novel framework for power system dynamic predictions by learning in the frequency domain. The intuition is that although the system behavior is complex in the time domain, there are relatively few dominate modes in the frequency domain. Therefore, we learn to predict by constructing neural networks with Fourier transform and filtering layers. System topology and fault information are encoded by taking a multi-dimensional Fourier transform, allowing us to leverage the fact that the trajectories are sparse both in time and spatial (across different buses) frequencies. We show that the proposed approach does not need detailed system parameters, speeds up prediction computations by orders of magnitude and is highly accurate for different fault types. Joint work with Microsoft Research.&lt;/p&gt;

&lt;ol class=&quot;bibliography&quot;&gt;&lt;/ol&gt;
</description>
        <pubDate>Sat, 15 Jan 2022 00:00:00 -0800</pubDate>
        <link>http://localhost:4000/blog/2022/01/Nature_sub</link>
        <guid isPermaLink="true">http://localhost:4000/blog/2022/01/Nature_sub</guid>
        
        
        <category>new</category>
        
        <category>papers</category>
        
      </item>
    
      <item>
        <title>Paper on A Lyapunov Approach for Optimal Frequency Control using Reinforcement Learning</title>
        <description>&lt;p&gt;As more inverter-connected renewable resources are integrated into the grid, frequency stability may degrade because of the reduction in mechanical inertia and damping. A common approach to mitigate this degradation in performance is to use the power electronic interfaces of the renewable resources for primary frequency control. Since inverter-connected resources can realize almost arbitrary responses to frequency changes, they are not limited to reproducing the linear droop behaviors. To fully leverage their capabilities, reinforcement learning (RL) has emerged as a popular method to design nonlinear controllers to optimize a host of objective functions.
Because both inverter-connected resources and synchronous generators would be a significant part of the grid in the near and intermediate future, the learned controller of the former should be stabilizing with respect to the nonlinear dynamics of the latter. To overcome this challenge, we explicitly engineer the structure of neural network-based controllers such that they guarantee system stability by construction, through the use of a Lyapunov function. A recurrent neural network architecture is used to efficiently train the controllers. The resulting controllers only use local information and outperform optimal linear droop as well as other state-of-the-art learning approaches.&lt;/p&gt;

&lt;ol class=&quot;bibliography&quot;&gt;&lt;/ol&gt;
</description>
        <pubDate>Fri, 10 Dec 2021 00:00:00 -0800</pubDate>
        <link>http://localhost:4000/blog/2021/12/Lya-copy</link>
        <guid isPermaLink="true">http://localhost:4000/blog/2021/12/Lya-copy</guid>
        
        
        <category>new</category>
        
        <category>papers</category>
        
      </item>
    
      <item>
        <title>Paper on Solving ACOPF Iteratively to get Global Optimal Solutions</title>
        <description>&lt;p&gt;The existence of multiple solutions to AC optimal power flow (ACOPF) problems has been noted for decades. Existing solvers are generally successful in finding local solutions, which are stationary points but may not be globally optimal. In this paper, we propose a simple iterative approach to find globally optimal solutions to ACOPF problems. First, we call an existing solver for the ACOPF problem. From the solution and the associated dual variables, we form a partial Lagrangian. Then we optimize this partial Lagrangian and use its solution as a warm start to call the solver again for the ACOPF problem. By repeating this process, we can iteratively improve the solution quality, moving from local solutions to global ones. We show the effectiveness our algorithm on standard IEEE networks. The simulation results show that our algorithm can escape from local solutions to achieve global optimums within a few iterations.&lt;/p&gt;

&lt;ol class=&quot;bibliography&quot;&gt;&lt;/ol&gt;
</description>
        <pubDate>Mon, 15 Mar 2021 00:00:00 -0700</pubDate>
        <link>http://localhost:4000/blog/2021/03/Iterative</link>
        <guid isPermaLink="true">http://localhost:4000/blog/2021/03/Iterative</guid>
        
        
        <category>new</category>
        
        <category>papers</category>
        
      </item>
    
  </channel>
</rss>
